{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f041b3b3-b487-4cca-919a-97e775b79942",
   "metadata": {},
   "source": [
    "# A decision support system for explainability techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d0fe64-d61c-40c1-89d9-14810ebf2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ciu import determine_ciu\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import time\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import tqdm\n",
    "from anchor import anchor_tabular\n",
    "import anchor_utils\n",
    "import metrics_rules\n",
    "import metrics\n",
    "from pymfe.mfe import MFE\n",
    "\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from skrules import SkopeRules\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a78fff-1d2d-4192-85ab-90a53dc418a4",
   "metadata": {},
   "source": [
    "## Reading in the datasets, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e04e12-042b-4b0e-a10a-db777988425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the datasets folder\n",
    "#datasets_folder = \"../datasets\"\n",
    "datasets_folder = \"datasets\"\n",
    "\n",
    "# Initialize empty lists to store dataframes for each file\n",
    "folder_names = []\n",
    "attribute_names_list = []\n",
    "categorical_indicator_list = []\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Loop through each folder in the datasets folder\n",
    "for folder_name in os.listdir(datasets_folder):\n",
    "    folder_path = os.path.join(datasets_folder, folder_name)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Construct file paths for each CSV file in the folder\n",
    "        attribute_names_path = os.path.join(folder_path, \"attribute_names.csv\")\n",
    "        categorical_indicator_path = os.path.join(folder_path, \"categorical_indicator.csv\")\n",
    "        X_path = os.path.join(folder_path, \"X.csv\")\n",
    "        y_path = os.path.join(folder_path, \"y.csv\")\n",
    "        \n",
    "        # Read each CSV file into a pandas dataframe\n",
    "        attribute_names_df = pd.read_csv(attribute_names_path)\n",
    "        categorical_indicator_df = pd.read_csv(categorical_indicator_path)\n",
    "        X_df = pd.read_csv(X_path)\n",
    "        y_df = pd.read_csv(y_path)\n",
    "        \n",
    "        # Append dataframes to the lists\n",
    "        attribute_names_list.append(attribute_names_df)\n",
    "        categorical_indicator_list.append(categorical_indicator_df)\n",
    "        X_list.append(X_df)\n",
    "        y_list.append(y_df)\n",
    "\n",
    "        # Save folder name to list\n",
    "        folder_names.append(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d391d4-d4a6-4172-bd2e-fa33ee81fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of rows: 500\n",
      "Max number of rows: 20000\n"
     ]
    }
   ],
   "source": [
    "nr_of_rows = []\n",
    "\n",
    "for i in range(len(X_list)):\n",
    "    nr_of_rows.append(len(X_list[i]))\n",
    "\n",
    "print(f\"Min number of rows: {min(nr_of_rows)}\")\n",
    "print(f\"Max number of rows: {max(nr_of_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b782e2-e09a-4c50-add3-120023849315",
   "metadata": {},
   "source": [
    "## Functions for explaining instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870333b4-372c-4b21-9039-3de896aa7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIU\n",
    "def exp_fn_ciu(xtest):\n",
    "    exp1 = []\n",
    "    for i in range(len(xtest)):\n",
    "        exp = determine_ciu(X_test.iloc[i:i+1], model.predict_proba, X_train.to_dict('list'), samples = 1000, prediction_index = 1)\n",
    "        exp_list = [[feat_list.index(i), exp.ci[i]] for i in exp.ci]\n",
    "        exp1.append(exp_list)\n",
    "    return np.array(exp1)\n",
    "\n",
    "# LIME\n",
    "def exp_fn_lime(xtest, exp_fn):\n",
    "    exp1 = []\n",
    "    for i in tqdm.tqdm(range(len(xtest))):\n",
    "        exp = exp_fn2(i)\n",
    "        exp1.append(exp.as_map()[exp.available_labels()[0]])\n",
    "    return np.array(exp1)\n",
    "\n",
    "# ANCHOR\n",
    "def exp_fn_anchor(xtest):\n",
    "    exp1 = []\n",
    "    for i in tqdm.tqdm(range(len(xtest))):\n",
    "        exp = anchor_explainer.explain_instance(X_test.values[i], model.predict, threshold=0.95)\n",
    "        exp_list = [0]*len(X_train.columns)\n",
    "        for j in exp.features():\n",
    "            exp_list[j] = 1\n",
    "        exp1.append(exp_list)\n",
    "    return np.array(exp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22127292-a1ca-4209-8b78-17c906bb0c48",
   "metadata": {},
   "source": [
    "## Interpreting instances and calculating quality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db65c02b-525b-4a15-ba84-d0bc11185bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 23.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 23.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:01<00:00,  9.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:01<00:00,  8.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:01<00:00, 10.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:01<00:00, 10.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:09<00:00,  1.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:09<00:00,  1.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:01<00:00,  9.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:01<00:00,  9.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:10<00:00,  1.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:10<00:00,  1.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 16.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 16.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 16.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 16.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:13<00:00,  1.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:15<00:00,  1.11s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 17.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 18.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:06<00:00,  2.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:08<00:00,  1.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 16.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 16.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:07<00:00,  1.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:07<00:00,  1.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 17.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 17.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  6.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  6.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 27.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 26.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:04<00:00,  2.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:04<00:00,  3.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:01<00:00, 10.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:01<00:00, 10.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:16<00:00,  1.15s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:14<00:00,  1.07s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.9982695  0.98823586 0.05264847 0.01438141].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:78\u001b[0m\n",
      "File \u001b[1;32m~\\Documents\\Seletatav automatiseeritud masinõpe\\Projekt\\metrics.py:54\u001b[0m, in \u001b[0;36mcalc_similarity\u001b[1;34m(exp, X_test_norm)\u001b[0m\n\u001b[0;32m     52\u001b[0m mean_dist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(labels):\n\u001b[1;32m---> 54\u001b[0m     mean_dist\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meuclidean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(mean_dist)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\automl2\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2196\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2194\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\automl2\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1766\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1763\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1769\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\automl2\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:310\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meuclidean_distances\u001b[39m(\n\u001b[0;32m    235\u001b[0m     X, Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, Y_norm_squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, X_norm_squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m ):\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m    Compute the distance matrix between each pair from a vector array X and Y.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m           [1.41421356]])\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X_norm_squared \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m         X_norm_squared \u001b[38;5;241m=\u001b[39m check_array(X_norm_squared, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\automl2\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:156\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    153\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype_float\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    166\u001b[0m         X,\n\u001b[0;32m    167\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    172\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\automl2\\lib\\site-packages\\sklearn\\utils\\validation.py:938\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    943\u001b[0m         )\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    949\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.9982695  0.98823586 0.05264847 0.01438141].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nr_of_exp_instances = 14\n",
    "interpretability_results = pd.DataFrame([])\n",
    "\n",
    "for i in range(20):\n",
    "    data_X = X_list[i]\n",
    "    data_y = y_list[i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    # Calculating meta-features\n",
    "    mfe = MFE(groups=[\"general\", \"statistical\"])\n",
    "    mfe.fit(np.array(data_X), np.array(data_y))\n",
    "    ft = mfe.extract()\n",
    "    df = pd.DataFrame(ft, columns = ft[0]).drop(0)\n",
    "\n",
    "    # Preprocessing data\n",
    "    le = LabelEncoder()\n",
    "    le_y = LabelEncoder()\n",
    "    imputer_cat = SimpleImputer(strategy = 'most_frequent')\n",
    "    imputer_num = SimpleImputer(strategy = 'mean')\n",
    "    for col in X_train.columns:\n",
    "        # Preprocessing categorical columns\n",
    "        if X_train[col].dtype == 'object':\n",
    "            le.fit(X_train[col])\n",
    "            X_train[col] = le.transform(X_train[col])\n",
    "            X_test[col] = le.transform(X_test[col])\n",
    "            imputer_cat.fit(X_train[col])\n",
    "            X_train[col] = imputer_cat.transform(X_train[col])\n",
    "            X_test[col] = imputer_cat.transform(X_test[col])\n",
    "        # Preprocessing numerical columns\n",
    "        else:\n",
    "            imputer_num.fit(X_train[col].values.reshape(-1, 1))\n",
    "            X_train[col] = imputer_num.transform(X_train[col].values.reshape(-1, 1))\n",
    "            X_test[col] = imputer_num.transform(X_test[col].values.reshape(-1, 1))\n",
    "    for col in y_train.columns:\n",
    "        # Preprocessing categorical columns\n",
    "        if y_train[col].dtype == 'object':\n",
    "            le_y.fit(y_train[col])\n",
    "            y_train[col] = le_y.transform(y_train[col])\n",
    "            y_test[col] = le_y.transform(y_test[col])\n",
    "\n",
    "    random_state = 42\n",
    "    exp_iter = 10\n",
    "    random.seed(random_state)\n",
    "    \n",
    "    test_x = X_test.values\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    class_names = np.unique(y_test)\n",
    "    feat_list = X_train.columns.tolist()\n",
    "    X = np.vstack((X_train.values, test_x))\n",
    "\n",
    "    # Fit GB model\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Dictionarys for quality measures results\n",
    "    df_identity = {}\n",
    "    df_separability = {}\n",
    "    df_similarity = {}\n",
    "    df_time = {}\n",
    "\n",
    "    \n",
    "    # ---- CIU - explaining and measuring quality ----\n",
    "    \n",
    "    # Explain\n",
    "    start_time = time.time()\n",
    "    exp1_ciu = exp_fn_ciu(X_test[:nr_of_exp_instances])\n",
    "    exp2_ciu = exp_fn_ciu(X_test[:nr_of_exp_instances])\n",
    "    time_ciu = time.time() - start_time\n",
    "    \n",
    "    # Save explanations\n",
    "    np.save('explanations/' + folder_names[i] + '_ciu1.npy', exp1_ciu)\n",
    "    np.save('explanations/' + folder_names[i] + '_ciu2.npy', exp2_ciu)\n",
    "    \n",
    "    # Quality measures\n",
    "    identity_ciu = metrics.calc_identity(exp1_ciu, exp2_ciu)[0]\n",
    "    separability_ciu = metrics.calc_separability(test_x[:nr_of_exp_instances])[3]\n",
    "    X_test_norm = metrics.normalize_test(X_train, X_test)\n",
    "    similarity_ciu = metrics.calc_similarity(exp1_ciu, X_test_norm[:nr_of_exp_instances])\n",
    "\n",
    "    # Save results to dict\n",
    "    df_identity['ciu'] = identity_ciu\n",
    "    df_separability['ciu'] = separability_ciu\n",
    "    df_similarity['ciu'] = time_ciu\n",
    "    df_time['ciu'] = similarity_ciu\n",
    "\n",
    "    \n",
    "    # ---- LIME - explaining and measuring quality ----\n",
    "\n",
    "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = feat_list, class_names=class_names, discretize_continuous=True)\n",
    "    exp_fn2 = lambda i: lime_explainer.explain_instance(X_test.iloc[i], model.predict_proba, num_features=len(X_test.columns))\n",
    "\n",
    "    # Explain\n",
    "    start_time = time.time()\n",
    "    exp1_lime = exp_fn_lime(test_x[:nr_of_exp_instances], exp_fn2)\n",
    "    exp2_lime = exp_fn_lime(test_x[:nr_of_exp_instances], exp_fn2)\n",
    "    time_lime = time.time() - start_time\n",
    "\n",
    "    # Save explanations\n",
    "    np.save('explanations/' + folder_names[i] + '_lime1.npy', exp1_lime)\n",
    "    np.save('explanations/' + folder_names[i] + '_lime2.npy', exp2_lime)\n",
    "\n",
    "    # Quality measures\n",
    "    identity_lime = metrics.calc_identity(exp1_lime, exp2_lime)[0]\n",
    "    separability_lime = metrics.calc_separability(test_x[:nr_of_exp_instances])[3]\n",
    "    similarity_lime = metrics.calc_similarity(exp1_lime, X_test_norm[:nr_of_exp_instances])\n",
    "\n",
    "    \n",
    "    # Save results to dict\n",
    "    df_identity['lime'] = identity_lime\n",
    "    df_separability['lime'] = separability_lime\n",
    "    df_similarity['lime'] = time_lime\n",
    "    df_time['lime'] = similarity_lime\n",
    "\n",
    "    \n",
    "    # ---- ANCHOR - explaining and measuring quality ----\n",
    "\n",
    "    anchor_explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "                        np.unique(y_train).tolist(),\n",
    "                        X_train.columns.tolist(),\n",
    "                        X_train.values\n",
    "                        )\n",
    "\n",
    "    # Explain\n",
    "    start_time = time.time()\n",
    "    exp1_anchor = exp_fn_anchor(X_test[:nr_of_exp_instances])\n",
    "    exp2_anchor = exp_fn_anchor(X_test[:nr_of_exp_instances])\n",
    "    time_anchor = time.time() - start_time\n",
    "\n",
    "    # Save explanations\n",
    "    np.save('explanations/' + folder_names[i] + '_anchor1.npy', exp1_anchor)\n",
    "    np.save('explanations/' + folder_names[i] + '_anchor2.npy', exp2_anchor)\n",
    "\n",
    "    # Quality measures\n",
    "    identity_anchor = metrics_rules.calc_identity_rules(exp1_anchor, exp2_anchor)[0]\n",
    "    separability_anchor = metrics_rules.calc_separability_rules(exp1_anchor)[3]\n",
    "    X_test_norm = metrics_rules.normalize_test(X_train, X_test)\n",
    "    similarity_anchor = metrics_rules.calc_similarity(exp1_anchor, X_test_norm[:nr_of_exp_instances])\n",
    "\n",
    "    # Save results to dict\n",
    "    df_identity['anchor'] = identity_anchor\n",
    "    df_separability['anchor'] = separability_anchor\n",
    "    df_similarity['anchor'] = time_anchor\n",
    "    df_time['anchor'] = similarity_anchor\n",
    "\n",
    "\n",
    "    # ---- RULEFIT - explaining and measuring quality ----\n",
    "\n",
    "    clf_rulefit = SkopeRules(max_depth_duplication = 2,\n",
    "                             n_estimators = 100,\n",
    "                             precision_min = 0.3,\n",
    "                             recall_min = 0.1,\n",
    "                             feature_names = X_train.columns.tolist())\n",
    "\n",
    "    clf_rulefit.fit(X_train, y_train)\n",
    "\n",
    "    # Explain\n",
    "    start_time = time.time()\n",
    "    top_rules1 = clf_rulefit.score_top_rules(X_test[:nr_of_exp_instances])\n",
    "    top_rules2 = clf_rulefit.score_top_rules(X_test[:nr_of_exp_instances])\n",
    "    time_rulefit = time.time() - start_time\n",
    "\n",
    "    # Save explanations\n",
    "    np.save('explanations/' + folder_names[i] + '_rulefit1.npy', top_rules1)\n",
    "    np.save('explanations/' + folder_names[i] + '_rulefit2.npy', top_rules2)\n",
    "\n",
    "    # Quality measures\n",
    "    identity_rulefit = metrics_rules.calc_identity_rules(top_rules1, top_rules2)[0]\n",
    "    separability_rulefit = metrics_rules.calc_separability_rules(top_rules1)[3]\n",
    "    enc_rules = metrics_rules.exp_enc(clf_rulefit, top_rules1)\n",
    "    similarity_rulefit = metrics_rules.calc_similarity(enc_rules, X_test_norm[:nr_of_exp_instances])\n",
    "\n",
    "    # Save results to dict\n",
    "    df_identity['rulefit'] = identity_rulefit\n",
    "    df_separability['rulefit'] = separability_rulefit\n",
    "    df_similarity['rulefit'] = time_rulefit\n",
    "    df_time['rulefit'] = similarity_rulefit\n",
    "\n",
    "\n",
    "    # ---- Selecting the best techniques based on quality measures ----\n",
    "\n",
    "    best_identity = max(df_identity, key=df_identity.get)\n",
    "    best_separability = max(df_separability, key=df_separability.get)\n",
    "    best_similarity = max(df_similarity, key=df_similarity.get)\n",
    "    best_time = max(df_time, key=df_time.get)\n",
    "\n",
    "    # Save results to dataframe\n",
    "    df['best_identity'] = best_identity\n",
    "    df['best_separability'] = best_separability\n",
    "    df['best_similarity'] = best_similarity\n",
    "    df['best_time'] = best_time\n",
    "\n",
    "    interpretability_results = pd.concat([interpretability_results, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94db5d33-02c9-4db5-acd4-4fbf1b9fc996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr_to_inst</th>\n",
       "      <th>can_cor.mean</th>\n",
       "      <th>can_cor.sd</th>\n",
       "      <th>cat_to_num</th>\n",
       "      <th>cor.mean</th>\n",
       "      <th>cor.sd</th>\n",
       "      <th>cov.mean</th>\n",
       "      <th>cov.sd</th>\n",
       "      <th>eigenvalues.mean</th>\n",
       "      <th>eigenvalues.sd</th>\n",
       "      <th>...</th>\n",
       "      <th>sparsity.sd</th>\n",
       "      <th>t_mean.mean</th>\n",
       "      <th>t_mean.sd</th>\n",
       "      <th>var.mean</th>\n",
       "      <th>var.sd</th>\n",
       "      <th>w_lambda</th>\n",
       "      <th>best_identity</th>\n",
       "      <th>best_separability</th>\n",
       "      <th>best_similarity</th>\n",
       "      <th>best_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.528956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15054</td>\n",
       "      <td>0.223382</td>\n",
       "      <td>23036992346.414856</td>\n",
       "      <td>72798303992.917099</td>\n",
       "      <td>121134480488.222824</td>\n",
       "      <td>234111523206.042114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223514</td>\n",
       "      <td>169541.676209</td>\n",
       "      <td>253212.170859</td>\n",
       "      <td>121134480488.222855</td>\n",
       "      <td>168245420225.651672</td>\n",
       "      <td>0.720205</td>\n",
       "      <td>lime</td>\n",
       "      <td>anchor</td>\n",
       "      <td>anchor</td>\n",
       "      <td>rulefit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025377</td>\n",
       "      <td>0.568092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350977</td>\n",
       "      <td>0.243944</td>\n",
       "      <td>469154.392907</td>\n",
       "      <td>8762157.949538</td>\n",
       "      <td>106280594.705627</td>\n",
       "      <td>646390558.822428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>142.832454</td>\n",
       "      <td>733.315812</td>\n",
       "      <td>106280594.705627</td>\n",
       "      <td>644186452.5723</td>\n",
       "      <td>0.677272</td>\n",
       "      <td>lime</td>\n",
       "      <td>anchor</td>\n",
       "      <td>anchor</td>\n",
       "      <td>ciu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023672</td>\n",
       "      <td>0.444716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405831</td>\n",
       "      <td>0.300664</td>\n",
       "      <td>12768345.744952</td>\n",
       "      <td>278742719.083171</td>\n",
       "      <td>3478069177.695143</td>\n",
       "      <td>21155909590.126251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021614</td>\n",
       "      <td>154.927167</td>\n",
       "      <td>789.092552</td>\n",
       "      <td>3478069177.695143</td>\n",
       "      <td>21087816087.780449</td>\n",
       "      <td>0.802228</td>\n",
       "      <td>ciu</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>212.247493</td>\n",
       "      <td>814.302136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04023</td>\n",
       "      <td>0.598582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775321</td>\n",
       "      <td>0.213983</td>\n",
       "      <td>5460267.115497</td>\n",
       "      <td>60240853.146294</td>\n",
       "      <td>613850878.368749</td>\n",
       "      <td>2812809834.503192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027386</td>\n",
       "      <td>128.417255</td>\n",
       "      <td>479.447053</td>\n",
       "      <td>613850878.368749</td>\n",
       "      <td>2799183414.518701</td>\n",
       "      <td>0.641699</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009957</td>\n",
       "      <td>0.467723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720347</td>\n",
       "      <td>0.221164</td>\n",
       "      <td>145365.769673</td>\n",
       "      <td>1304494.7814</td>\n",
       "      <td>14549820.294238</td>\n",
       "      <td>66667325.946777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020748</td>\n",
       "      <td>42.756092</td>\n",
       "      <td>144.029936</td>\n",
       "      <td>14549820.294238</td>\n",
       "      <td>66396708.690128</td>\n",
       "      <td>0.781235</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018936</td>\n",
       "      <td>0.386223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.632733</td>\n",
       "      <td>0.227349</td>\n",
       "      <td>9113908.170039</td>\n",
       "      <td>112468708.576845</td>\n",
       "      <td>1391021745.093177</td>\n",
       "      <td>6374271207.053247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012391</td>\n",
       "      <td>266.343759</td>\n",
       "      <td>1033.984479</td>\n",
       "      <td>1391021745.093177</td>\n",
       "      <td>6353362935.781049</td>\n",
       "      <td>0.850831</td>\n",
       "      <td>ciu</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.423927</td>\n",
       "      <td>0.56381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.003205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.003205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323122</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "      <td>rulefit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.572295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278781</td>\n",
       "      <td>0.272877</td>\n",
       "      <td>152.216247</td>\n",
       "      <td>305.82708</td>\n",
       "      <td>1493.801871</td>\n",
       "      <td>2166.19809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>29.270102</td>\n",
       "      <td>58.628622</td>\n",
       "      <td>1493.801871</td>\n",
       "      <td>1883.135357</td>\n",
       "      <td>0.672478</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.303627</td>\n",
       "      <td>0.218076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256451</td>\n",
       "      <td>0.16084</td>\n",
       "      <td>24.699359</td>\n",
       "      <td>28.692798</td>\n",
       "      <td>104.816879</td>\n",
       "      <td>119.529302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043015</td>\n",
       "      <td>14.296274</td>\n",
       "      <td>13.098502</td>\n",
       "      <td>104.816879</td>\n",
       "      <td>67.292901</td>\n",
       "      <td>0.327596</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  attr_to_inst can_cor.mean can_cor.sd cat_to_num  cor.mean    cor.sd  \\\n",
       "1     0.000322     0.528956        NaN        0.0   0.15054  0.223382   \n",
       "1     0.025377     0.568092        NaN        0.0  0.350977  0.243944   \n",
       "1     0.023672     0.444716        NaN        0.0  0.405831  0.300664   \n",
       "1     0.001929          NaN        NaN        0.0       NaN       NaN   \n",
       "1      0.04023     0.598582        NaN        0.0  0.775321  0.213983   \n",
       "1     0.009957     0.467723        NaN        0.0  0.720347  0.221164   \n",
       "1     0.018936     0.386223        NaN        0.0  0.632733  0.227349   \n",
       "1       0.0064     0.423927    0.56381        0.0       0.0       0.0   \n",
       "1     0.000526     0.572295        NaN        0.0  0.278781  0.272877   \n",
       "1     0.000685     0.303627   0.218076        0.0  0.256451   0.16084   \n",
       "\n",
       "             cov.mean              cov.sd     eigenvalues.mean  \\\n",
       "1  23036992346.414856  72798303992.917099  121134480488.222824   \n",
       "1       469154.392907      8762157.949538     106280594.705627   \n",
       "1     12768345.744952    278742719.083171    3478069177.695143   \n",
       "1                 NaN                 NaN                  NaN   \n",
       "1      5460267.115497     60240853.146294     613850878.368749   \n",
       "1       145365.769673        1304494.7814      14549820.294238   \n",
       "1      9113908.170039    112468708.576845    1391021745.093177   \n",
       "1                 0.0                 0.0             2.003205   \n",
       "1          152.216247           305.82708          1493.801871   \n",
       "1           24.699359           28.692798           104.816879   \n",
       "\n",
       "        eigenvalues.sd  ... sparsity.sd    t_mean.mean      t_mean.sd  \\\n",
       "1  234111523206.042114  ...    0.223514  169541.676209  253212.170859   \n",
       "1     646390558.822428  ...    0.086522     142.832454     733.315812   \n",
       "1   21155909590.126251  ...    0.021614     154.927167     789.092552   \n",
       "1                  NaN  ...    0.008187     212.247493     814.302136   \n",
       "1    2812809834.503192  ...    0.027386     128.417255     479.447053   \n",
       "1      66667325.946777  ...    0.020748      42.756092     144.029936   \n",
       "1    6374271207.053247  ...    0.012391     266.343759    1033.984479   \n",
       "1                  0.0  ...         0.0            3.0            0.0   \n",
       "1           2166.19809  ...    0.000062      29.270102      58.628622   \n",
       "1           119.529302  ...    0.043015      14.296274      13.098502   \n",
       "\n",
       "              var.mean               var.sd  w_lambda best_identity  \\\n",
       "1  121134480488.222855  168245420225.651672  0.720205          lime   \n",
       "1     106280594.705627       644186452.5723  0.677272          lime   \n",
       "1    3478069177.695143   21087816087.780449  0.802228           ciu   \n",
       "1                  NaN                  NaN       NaN          lime   \n",
       "1     613850878.368749    2799183414.518701  0.641699          lime   \n",
       "1      14549820.294238      66396708.690128  0.781235          lime   \n",
       "1    1391021745.093177    6353362935.781049  0.850831           ciu   \n",
       "1             2.003205                  0.0  0.323122          lime   \n",
       "1          1493.801871          1883.135357  0.672478          lime   \n",
       "1           104.816879            67.292901  0.327596          lime   \n",
       "\n",
       "  best_separability best_similarity best_time  \n",
       "1            anchor          anchor   rulefit  \n",
       "1            anchor          anchor       ciu  \n",
       "1           rulefit          anchor    anchor  \n",
       "1           rulefit          anchor    anchor  \n",
       "1           rulefit          anchor    anchor  \n",
       "1           rulefit          anchor    anchor  \n",
       "1           rulefit          anchor    anchor  \n",
       "1           rulefit          anchor   rulefit  \n",
       "1           rulefit          anchor    anchor  \n",
       "1           rulefit          anchor    anchor  \n",
       "\n",
       "[10 rows x 64 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretability_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b95431ee-9aa3-49b0-b9ca-6d477ccb67b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretability_results.to_csv('interpretability_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a372d54c-6043-4933-a6cb-1071aa3feab1",
   "metadata": {},
   "source": [
    "## Interpreting instances and calculating quality measures (without similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35759d98-d048-4780-bf72-7969011e794a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:08<00:00,  2.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:10<00:00,  2.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  5.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  5.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:31<00:00,  1.27s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:29<00:00,  1.19s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:25<00:00,  1.03s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:25<00:00,  1.01s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  5.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  5.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:20<00:00,  1.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:16<00:00,  1.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  7.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:51<00:00,  2.06s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:21<00:00,  3.24s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  7.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  8.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:21<00:00,  1.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:19<00:00,  1.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  7.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  7.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:19<00:00,  1.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:20<00:00,  1.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  5.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  6.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:11<00:00,  2.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:11<00:00,  2.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:02<00:00, 11.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 12.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:18<00:00,  1.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:19<00:00,  1.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  5.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  5.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:39<00:00,  1.60s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:39<00:00,  1.59s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 12.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 12.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  6.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  6.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:02<00:00, 12.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:02<00:00, 11.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:11<00:00,  2.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:08<00:00,  2.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:07<00:00,  2.69s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [01:23<00:00,  3.35s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  7.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  7.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:38<00:00,  1.53s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:57<00:00,  2.31s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  7.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  7.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:57<00:00,  2.32s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:54<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 28min 14s\n",
      "Wall time: 29min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nr_of_exp_instances = 25\n",
    "interpretability_results2 = pd.DataFrame([])\n",
    "\n",
    "for i in range(15):\n",
    "    data_X = X_list[i]\n",
    "    data_y = y_list[i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    # Calculating meta-features\n",
    "    mfe = MFE(groups=[\"general\", \"statistical\"])\n",
    "    mfe.fit(np.array(data_X), np.array(data_y))\n",
    "    ft = mfe.extract()\n",
    "    df = pd.DataFrame(ft, columns = ft[0]).drop(0)\n",
    "\n",
    "    # Preprocessing data\n",
    "    le = LabelEncoder()\n",
    "    le_y = LabelEncoder()\n",
    "    imputer_cat = SimpleImputer(strategy = 'most_frequent')\n",
    "    imputer_num = SimpleImputer(strategy = 'mean')\n",
    "    for col in X_train.columns:\n",
    "        # Preprocessing categorical columns\n",
    "        if X_train[col].dtype == 'object':\n",
    "            le.fit(X_train[col])\n",
    "            X_train[col] = le.transform(X_train[col])\n",
    "            X_test[col] = le.transform(X_test[col])\n",
    "            imputer_cat.fit(X_train[col])\n",
    "            X_train[col] = imputer_cat.transform(X_train[col])\n",
    "            X_test[col] = imputer_cat.transform(X_test[col])\n",
    "        # Preprocessing numerical columns\n",
    "        else:\n",
    "            imputer_num.fit(X_train[col].values.reshape(-1, 1))\n",
    "            X_train[col] = imputer_num.transform(X_train[col].values.reshape(-1, 1))\n",
    "            X_test[col] = imputer_num.transform(X_test[col].values.reshape(-1, 1))\n",
    "    for col in y_train.columns:\n",
    "        # Preprocessing categorical columns\n",
    "        if y_train[col].dtype == 'object':\n",
    "            le_y.fit(y_train[col])\n",
    "            y_train[col] = le_y.transform(y_train[col])\n",
    "            y_test[col] = le_y.transform(y_test[col])\n",
    "\n",
    "    random_state = 42\n",
    "    exp_iter = 10\n",
    "    random.seed(random_state)\n",
    "    \n",
    "    test_x = X_test.values\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    class_names = np.unique(y_test)\n",
    "    feat_list = X_train.columns.tolist()\n",
    "    X = np.vstack((X_train.values, test_x))\n",
    "\n",
    "    # Fit GB model\n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Dictionarys for quality measures results\n",
    "    df_identity = {}\n",
    "    df_separability = {}\n",
    "    #df_similarity = {}\n",
    "    df_time = {}\n",
    "\n",
    "    \n",
    "    # ---- CIU - explaining and measuring quality ----\n",
    "    \n",
    "    # Explain\n",
    "    start_time = time.time()\n",
    "    exp1_ciu = exp_fn_ciu(X_test[:nr_of_exp_instances])\n",
    "    exp2_ciu = exp_fn_ciu(X_test[:nr_of_exp_instances])\n",
    "    time_ciu = time.time() - start_time\n",
    "    \n",
    "    # Save explanations\n",
    "    np.save('explanations2/' + folder_names[i] + '_ciu1.npy', exp1_ciu)\n",
    "    np.save('explanations2/' + folder_names[i] + '_ciu2.npy', exp2_ciu)\n",
    "    \n",
    "    # Quality measures\n",
    "    identity_ciu = metrics.calc_identity(exp1_ciu, exp2_ciu)[0]\n",
    "    separability_ciu = metrics.calc_separability(test_x[:nr_of_exp_instances])[3]\n",
    "    #X_test_norm = metrics.normalize_test(X_train, X_test)\n",
    "    #similarity_ciu = metrics.calc_similarity(exp1_ciu, X_test_norm[:nr_of_exp_instances])\n",
    "\n",
    "    # Save results to dict\n",
    "    df_identity['ciu'] = identity_ciu\n",
    "    df_separability['ciu'] = separability_ciu\n",
    "    #df_similarity['ciu'] = time_ciu\n",
    "    df_time['ciu'] = similarity_ciu\n",
    "\n",
    "    \n",
    "    # ---- LIME - explaining and measuring quality ----\n",
    "\n",
    "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names = feat_list, class_names=class_names, discretize_continuous=True)\n",
    "    exp_fn2 = lambda i: lime_explainer.explain_instance(X_test.iloc[i], model.predict_proba, num_features=len(X_test.columns))\n",
    "\n",
    "    # Explain\n",
    "    start_time = time.time()\n",
    "    exp1_lime = exp_fn_lime(test_x[:nr_of_exp_instances], exp_fn2)\n",
    "    exp2_lime = exp_fn_lime(test_x[:nr_of_exp_instances], exp_fn2)\n",
    "    time_lime = time.time() - start_time\n",
    "\n",
    "    # Save explanations\n",
    "    np.save('explanations2/' + folder_names[i] + '_lime1.npy', exp1_lime)\n",
    "    np.save('explanations2/' + folder_names[i] + '_lime2.npy', exp2_lime)\n",
    "\n",
    "    # Quality measures\n",
    "    identity_lime = metrics.calc_identity(exp1_lime, exp2_lime)[0]\n",
    "    separability_lime = metrics.calc_separability(test_x[:nr_of_exp_instances])[3]\n",
    "    #similarity_lime = metrics.calc_similarity(exp1_lime, X_test_norm[:nr_of_exp_instances])\n",
    "\n",
    "    \n",
    "    # Save results to dict\n",
    "    df_identity['lime'] = identity_lime\n",
    "    df_separability['lime'] = separability_lime\n",
    "    #df_similarity['lime'] = time_lime\n",
    "    df_time['lime'] = similarity_lime\n",
    "\n",
    "    \n",
    "    # ---- ANCHOR - explaining and measuring quality ----\n",
    "\n",
    "    anchor_explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "                        np.unique(y_train).tolist(),\n",
    "                        X_train.columns.tolist(),\n",
    "                        X_train.values\n",
    "                        )\n",
    "\n",
    "    # Explain\n",
    "    start_time = time.time()\n",
    "    exp1_anchor = exp_fn_anchor(X_test[:nr_of_exp_instances])\n",
    "    exp2_anchor = exp_fn_anchor(X_test[:nr_of_exp_instances])\n",
    "    time_anchor = time.time() - start_time\n",
    "\n",
    "    # Save explanations\n",
    "    np.save('explanations2/' + folder_names[i] + '_anchor1.npy', exp1_anchor)\n",
    "    np.save('explanations2/' + folder_names[i] + '_anchor2.npy', exp2_anchor)\n",
    "\n",
    "    # Quality measures\n",
    "    identity_anchor = metrics_rules.calc_identity_rules(exp1_anchor, exp2_anchor)[0]\n",
    "    separability_anchor = metrics_rules.calc_separability_rules(exp1_anchor)[3]\n",
    "    #X_test_norm = metrics_rules.normalize_test(X_train, X_test)\n",
    "    #similarity_anchor = metrics_rules.calc_similarity(exp1_anchor, X_test_norm[:nr_of_exp_instances])\n",
    "\n",
    "    # Save results to dict\n",
    "    df_identity['anchor'] = identity_anchor\n",
    "    df_separability['anchor'] = separability_anchor\n",
    "    #df_similarity['anchor'] = time_anchor\n",
    "    df_time['anchor'] = similarity_anchor\n",
    "\n",
    "\n",
    "    # ---- RULEFIT - explaining and measuring quality ----\n",
    "\n",
    "    clf_rulefit = SkopeRules(max_depth_duplication = 2,\n",
    "                             n_estimators = 100,\n",
    "                             precision_min = 0.3,\n",
    "                             recall_min = 0.1,\n",
    "                             feature_names = X_train.columns.tolist())\n",
    "\n",
    "    clf_rulefit.fit(X_train, y_train)\n",
    "\n",
    "    # Explain\n",
    "    start_time = time.time()\n",
    "    top_rules1 = clf_rulefit.score_top_rules(X_test[:nr_of_exp_instances])\n",
    "    top_rules2 = clf_rulefit.score_top_rules(X_test[:nr_of_exp_instances])\n",
    "    time_rulefit = time.time() - start_time\n",
    "\n",
    "    # Save explanations\n",
    "    np.save('explanations2/' + folder_names[i] + '_rulefit1.npy', top_rules1)\n",
    "    np.save('explanations2/' + folder_names[i] + '_rulefit2.npy', top_rules2)\n",
    "\n",
    "    # Quality measures\n",
    "    identity_rulefit = metrics_rules.calc_identity_rules(top_rules1, top_rules2)[0]\n",
    "    separability_rulefit = metrics_rules.calc_separability_rules(top_rules1)[3]\n",
    "    #enc_rules = metrics_rules.exp_enc(clf_rulefit, top_rules1)\n",
    "    #similarity_rulefit = metrics_rules.calc_similarity(enc_rules, X_test_norm[:nr_of_exp_instances])\n",
    "\n",
    "    # Save results to dict\n",
    "    df_identity['rulefit'] = identity_rulefit\n",
    "    df_separability['rulefit'] = separability_rulefit\n",
    "    #df_similarity['rulefit'] = time_rulefit\n",
    "    df_time['rulefit'] = similarity_rulefit\n",
    "\n",
    "\n",
    "    # ---- Selecting the best techniques based on quality measures ----\n",
    "\n",
    "    best_identity = max(df_identity, key=df_identity.get)\n",
    "    best_separability = max(df_separability, key=df_separability.get)\n",
    "    #best_similarity = max(df_similarity, key=df_similarity.get)\n",
    "    best_time = max(df_time, key=df_time.get)\n",
    "\n",
    "    # Save results to dataframe\n",
    "    df['best_identity'] = best_identity\n",
    "    df['best_separability'] = best_separability\n",
    "    #df['best_similarity'] = best_similarity\n",
    "    df['best_time'] = best_time\n",
    "\n",
    "    interpretability_results2 = pd.concat([interpretability_results2, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c41efad-6182-47f8-9eeb-071c3efc90fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr_to_inst</th>\n",
       "      <th>can_cor.mean</th>\n",
       "      <th>can_cor.sd</th>\n",
       "      <th>cat_to_num</th>\n",
       "      <th>cor.mean</th>\n",
       "      <th>cor.sd</th>\n",
       "      <th>cov.mean</th>\n",
       "      <th>cov.sd</th>\n",
       "      <th>eigenvalues.mean</th>\n",
       "      <th>eigenvalues.sd</th>\n",
       "      <th>...</th>\n",
       "      <th>sparsity.mean</th>\n",
       "      <th>sparsity.sd</th>\n",
       "      <th>t_mean.mean</th>\n",
       "      <th>t_mean.sd</th>\n",
       "      <th>var.mean</th>\n",
       "      <th>var.sd</th>\n",
       "      <th>w_lambda</th>\n",
       "      <th>best_identity</th>\n",
       "      <th>best_separability</th>\n",
       "      <th>best_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.528956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15054</td>\n",
       "      <td>0.223382</td>\n",
       "      <td>23036992346.414856</td>\n",
       "      <td>72798303992.917099</td>\n",
       "      <td>121134480488.222824</td>\n",
       "      <td>234111523206.042114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100133</td>\n",
       "      <td>0.223514</td>\n",
       "      <td>169541.676209</td>\n",
       "      <td>253212.170859</td>\n",
       "      <td>121134480488.222855</td>\n",
       "      <td>168245420225.651672</td>\n",
       "      <td>0.720205</td>\n",
       "      <td>ciu</td>\n",
       "      <td>anchor</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025377</td>\n",
       "      <td>0.568092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350977</td>\n",
       "      <td>0.243944</td>\n",
       "      <td>469154.392907</td>\n",
       "      <td>8762157.949538</td>\n",
       "      <td>106280594.705627</td>\n",
       "      <td>646390558.822428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036344</td>\n",
       "      <td>0.086522</td>\n",
       "      <td>142.832454</td>\n",
       "      <td>733.315812</td>\n",
       "      <td>106280594.705627</td>\n",
       "      <td>644186452.5723</td>\n",
       "      <td>0.677272</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023672</td>\n",
       "      <td>0.444716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405831</td>\n",
       "      <td>0.300664</td>\n",
       "      <td>12768345.744952</td>\n",
       "      <td>278742719.083171</td>\n",
       "      <td>3478069177.695143</td>\n",
       "      <td>21155909590.126251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>0.021614</td>\n",
       "      <td>154.927167</td>\n",
       "      <td>789.092552</td>\n",
       "      <td>3478069177.695143</td>\n",
       "      <td>21087816087.780449</td>\n",
       "      <td>0.802228</td>\n",
       "      <td>ciu</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>212.247493</td>\n",
       "      <td>814.302136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04023</td>\n",
       "      <td>0.598582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775321</td>\n",
       "      <td>0.213983</td>\n",
       "      <td>5460267.115497</td>\n",
       "      <td>60240853.146294</td>\n",
       "      <td>613850878.368749</td>\n",
       "      <td>2812809834.503192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020273</td>\n",
       "      <td>0.027386</td>\n",
       "      <td>128.417255</td>\n",
       "      <td>479.447053</td>\n",
       "      <td>613850878.368749</td>\n",
       "      <td>2799183414.518701</td>\n",
       "      <td>0.641699</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009957</td>\n",
       "      <td>0.467723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720347</td>\n",
       "      <td>0.221164</td>\n",
       "      <td>145365.769673</td>\n",
       "      <td>1304494.7814</td>\n",
       "      <td>14549820.294238</td>\n",
       "      <td>66667325.946777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018697</td>\n",
       "      <td>0.020748</td>\n",
       "      <td>42.756092</td>\n",
       "      <td>144.029936</td>\n",
       "      <td>14549820.294238</td>\n",
       "      <td>66396708.690128</td>\n",
       "      <td>0.781235</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018936</td>\n",
       "      <td>0.386223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.632733</td>\n",
       "      <td>0.227349</td>\n",
       "      <td>9113908.170039</td>\n",
       "      <td>112468708.576845</td>\n",
       "      <td>1391021745.093177</td>\n",
       "      <td>6374271207.053247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012637</td>\n",
       "      <td>0.012391</td>\n",
       "      <td>266.343759</td>\n",
       "      <td>1033.984479</td>\n",
       "      <td>1391021745.093177</td>\n",
       "      <td>6353362935.781049</td>\n",
       "      <td>0.850831</td>\n",
       "      <td>ciu</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.423927</td>\n",
       "      <td>0.56381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.003205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.003205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323122</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.572295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278781</td>\n",
       "      <td>0.272877</td>\n",
       "      <td>152.216247</td>\n",
       "      <td>305.82708</td>\n",
       "      <td>1493.801871</td>\n",
       "      <td>2166.19809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>29.270102</td>\n",
       "      <td>58.628622</td>\n",
       "      <td>1493.801871</td>\n",
       "      <td>1883.135357</td>\n",
       "      <td>0.672478</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.303627</td>\n",
       "      <td>0.218076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256451</td>\n",
       "      <td>0.16084</td>\n",
       "      <td>24.699359</td>\n",
       "      <td>28.692798</td>\n",
       "      <td>104.816879</td>\n",
       "      <td>119.529302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>0.043015</td>\n",
       "      <td>14.296274</td>\n",
       "      <td>13.098502</td>\n",
       "      <td>104.816879</td>\n",
       "      <td>67.292901</td>\n",
       "      <td>0.327596</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.929974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425625</td>\n",
       "      <td>0.201158</td>\n",
       "      <td>6.667856</td>\n",
       "      <td>6.690612</td>\n",
       "      <td>16.379406</td>\n",
       "      <td>22.541872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.687509</td>\n",
       "      <td>1.276218</td>\n",
       "      <td>16.379406</td>\n",
       "      <td>13.456613</td>\n",
       "      <td>0.135148</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.359244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465998</td>\n",
       "      <td>0.345243</td>\n",
       "      <td>5568.26657</td>\n",
       "      <td>8964.729361</td>\n",
       "      <td>532947.021751</td>\n",
       "      <td>1065615.408105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>267.449444</td>\n",
       "      <td>506.647734</td>\n",
       "      <td>532947.021751</td>\n",
       "      <td>1065431.503059</td>\n",
       "      <td>0.870944</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166564</td>\n",
       "      <td>0.167631</td>\n",
       "      <td>1402.717761</td>\n",
       "      <td>32240.681321</td>\n",
       "      <td>47793.721853</td>\n",
       "      <td>273716.99107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18683</td>\n",
       "      <td>0.223832</td>\n",
       "      <td>94.904792</td>\n",
       "      <td>278.825566</td>\n",
       "      <td>47793.721853</td>\n",
       "      <td>196295.990217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.433546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>2.837166</td>\n",
       "      <td>34.682157</td>\n",
       "      <td>1352.600649</td>\n",
       "      <td>5447.659158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>0.07422</td>\n",
       "      <td>18.575006</td>\n",
       "      <td>62.604915</td>\n",
       "      <td>1352.600649</td>\n",
       "      <td>5445.447538</td>\n",
       "      <td>0.812038</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.293101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306039</td>\n",
       "      <td>0.255873</td>\n",
       "      <td>716516.925416</td>\n",
       "      <td>3176922.617487</td>\n",
       "      <td>7420472.11391</td>\n",
       "      <td>16795382.498207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>4299.399391</td>\n",
       "      <td>195.183426</td>\n",
       "      <td>7420472.11391</td>\n",
       "      <td>11625418.012142</td>\n",
       "      <td>0.914092</td>\n",
       "      <td>lime</td>\n",
       "      <td>rulefit</td>\n",
       "      <td>anchor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  attr_to_inst can_cor.mean can_cor.sd cat_to_num  cor.mean    cor.sd  \\\n",
       "1     0.000322     0.528956        NaN        0.0   0.15054  0.223382   \n",
       "1     0.025377     0.568092        NaN        0.0  0.350977  0.243944   \n",
       "1     0.023672     0.444716        NaN        0.0  0.405831  0.300664   \n",
       "1     0.001929          NaN        NaN        0.0       NaN       NaN   \n",
       "1      0.04023     0.598582        NaN        0.0  0.775321  0.213983   \n",
       "1     0.009957     0.467723        NaN        0.0  0.720347  0.221164   \n",
       "1     0.018936     0.386223        NaN        0.0  0.632733  0.227349   \n",
       "1       0.0064     0.423927    0.56381        0.0       0.0       0.0   \n",
       "1     0.000526     0.572295        NaN        0.0  0.278781  0.272877   \n",
       "1     0.000685     0.303627   0.218076        0.0  0.256451   0.16084   \n",
       "1     0.002915     0.929974        NaN        0.0  0.425625  0.201158   \n",
       "1     0.005348     0.359244        NaN        0.0  0.465998  0.345243   \n",
       "1     0.016463          1.0        0.0        0.0  0.166564  0.167631   \n",
       "1     0.037037     0.433546        NaN        0.0  0.017047    0.0734   \n",
       "1     0.000935     0.293101        NaN        0.0  0.306039  0.255873   \n",
       "\n",
       "             cov.mean              cov.sd     eigenvalues.mean  \\\n",
       "1  23036992346.414856  72798303992.917099  121134480488.222824   \n",
       "1       469154.392907      8762157.949538     106280594.705627   \n",
       "1     12768345.744952    278742719.083171    3478069177.695143   \n",
       "1                 NaN                 NaN                  NaN   \n",
       "1      5460267.115497     60240853.146294     613850878.368749   \n",
       "1       145365.769673        1304494.7814      14549820.294238   \n",
       "1      9113908.170039    112468708.576845    1391021745.093177   \n",
       "1                 0.0                 0.0             2.003205   \n",
       "1          152.216247           305.82708          1493.801871   \n",
       "1           24.699359           28.692798           104.816879   \n",
       "1            6.667856            6.690612            16.379406   \n",
       "1          5568.26657         8964.729361        532947.021751   \n",
       "1         1402.717761        32240.681321         47793.721853   \n",
       "1            2.837166           34.682157          1352.600649   \n",
       "1       716516.925416      3176922.617487        7420472.11391   \n",
       "\n",
       "        eigenvalues.sd  ... sparsity.mean sparsity.sd    t_mean.mean  \\\n",
       "1  234111523206.042114  ...      0.100133    0.223514  169541.676209   \n",
       "1     646390558.822428  ...      0.036344    0.086522     142.832454   \n",
       "1   21155909590.126251  ...      0.016497    0.021614     154.927167   \n",
       "1                  NaN  ...      0.007105    0.008187     212.247493   \n",
       "1    2812809834.503192  ...      0.020273    0.027386     128.417255   \n",
       "1      66667325.946777  ...      0.018697    0.020748      42.756092   \n",
       "1    6374271207.053247  ...      0.012637    0.012391     266.343759   \n",
       "1                  0.0  ...      0.198718         0.0            3.0   \n",
       "1           2166.19809  ...      0.000037    0.000062      29.270102   \n",
       "1           119.529302  ...      0.029054    0.043015      14.296274   \n",
       "1            22.541872  ...       0.00007    0.000049       0.687509   \n",
       "1       1065615.408105  ...      0.025118    0.009126     267.449444   \n",
       "1         273716.99107  ...       0.18683    0.223832      94.904792   \n",
       "1          5447.659158  ...      0.016791     0.07422      18.575006   \n",
       "1      16795382.498207  ...      0.002683    0.000648    4299.399391   \n",
       "\n",
       "       t_mean.sd             var.mean               var.sd  w_lambda  \\\n",
       "1  253212.170859  121134480488.222855  168245420225.651672  0.720205   \n",
       "1     733.315812     106280594.705627       644186452.5723  0.677272   \n",
       "1     789.092552    3478069177.695143   21087816087.780449  0.802228   \n",
       "1     814.302136                  NaN                  NaN       NaN   \n",
       "1     479.447053     613850878.368749    2799183414.518701  0.641699   \n",
       "1     144.029936      14549820.294238      66396708.690128  0.781235   \n",
       "1    1033.984479    1391021745.093177    6353362935.781049  0.850831   \n",
       "1            0.0             2.003205                  0.0  0.323122   \n",
       "1      58.628622          1493.801871          1883.135357  0.672478   \n",
       "1      13.098502           104.816879            67.292901  0.327596   \n",
       "1       1.276218            16.379406            13.456613  0.135148   \n",
       "1     506.647734        532947.021751       1065431.503059  0.870944   \n",
       "1     278.825566         47793.721853        196295.990217       0.0   \n",
       "1      62.604915          1352.600649          5445.447538  0.812038   \n",
       "1     195.183426        7420472.11391      11625418.012142  0.914092   \n",
       "\n",
       "  best_identity best_separability best_time  \n",
       "1           ciu            anchor    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1           ciu           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1           ciu           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "1          lime           rulefit    anchor  \n",
       "\n",
       "[15 rows x 63 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretability_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b41ce72-b190-4fbb-8f58-97da6388206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretability_results2.to_csv('interpretability_results2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
